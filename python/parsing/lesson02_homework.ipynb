{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fd9baac",
   "metadata": {},
   "source": [
    "# Методы сбора и обработки данных из сети Интернет\n",
    "### Урок 2. Парсинг HTML. Библиотека Beautiful soup.\n",
    "Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы получаем должность) с сайтов HH(обязательно) и/или Superjob(по желанию). Приложение должно анализировать несколько страниц сайта (также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:\n",
    "\n",
    "- Наименование вакансии.\n",
    "- Предлагаемую зарплату (разносим в три поля: минимальная и максимальная и валюта. цифры преобразуем к цифрам).\n",
    "- Ссылку на саму вакансию.\n",
    "- Сайт, откуда собрана вакансия.\n",
    "\n",
    "По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas. Сохраните в json либо csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15099bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "# https://hh.ru/search/vacancy?text=Data+scientist&area=1&salary=&currency_code=RUR&experience=doesNotMatter&order_by=relevance&search_period=0&items_on_page=50&no_magic=true&L_save_area=true&from=suggest_post\n",
    "main_url = 'https://hh.ru'\n",
    "vacancy = 'Data Scientist'\n",
    "page = 0\n",
    "all_vacancies = []\n",
    "params = {'text': vacancy,\n",
    "          'area': 1,\n",
    "          'experience': 'doesNotMatter',\n",
    "          'order_by': 'relevance',\n",
    "          'search_period': 0,\n",
    "          'items_on_page': 20,\n",
    "          'page': page}\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "                         'AppleWebKit/537.36 (KHTML, like Gecko)'\n",
    "                         'Chrome/98.0.4758.141 YaBrowser/22.3.4.731 Yowser/2.5 Safari/537.36'}\n",
    "response = requests.get(main_url + '/search/vacancy', params=params, headers=headers)\n",
    "soup = bs(response.text, 'html.parser')\n",
    "try:\n",
    "    # Получаем последнюю страничку\n",
    "    last_page = int(soup.find_all('a',{'data-qa':'pager-page'})[-1].text)\n",
    "except:\n",
    "    last_page = 1\n",
    "\n",
    "for i in range(last_page):\n",
    "\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "\n",
    "    vacancies = soup.find_all('div', {'class': 'vacancy-serp-item'})\n",
    "\n",
    "    for vacancy in vacancies:\n",
    "\n",
    "        vacancy_info = {}\n",
    "                vacancy_anchor = vacancy.find('a', {'data-qa': \"vacancy-serp__vacancy-title\"})\n",
    "        vacancy_name = vacancy_anchor.getText()\n",
    "        vacancy_info['name'] = vacancy_name\n",
    "\n",
    "        vacancy_link = vacancy_anchor['href']\n",
    "        vacancy_info['link'] = vacancy_link\n",
    "\n",
    "        vacancy_info['site'] = main_url + '/'\n",
    "\n",
    "        vacancy_salary = vacancy.find('span', {'data-qa': \"vacancy-serp__vacancy-compensation\"})\n",
    "        if vacancy_salary is None:\n",
    "            min_salary = None\n",
    "            max_salary = None\n",
    "            currency = None\n",
    "        else:\n",
    "            vacancy_salary = vacancy_salary.getText()\n",
    "            if vacancy_salary.startswith('РґРѕ'):\n",
    "                max_salary = int(\"\".join([s for s in vacancy_salary.split() if s.isdigit()]))\n",
    "                min_salary = None\n",
    "                currency = vacancy_salary.split()[-1]\n",
    "\n",
    "            elif vacancy_salary.startswith('РѕС‚'):\n",
    "                max_salary = None\n",
    "                min_salary = int(\"\".join([s for s in vacancy_salary.split() if s.isdigit()]))\n",
    "                currency = vacancy_salary.split()[-1]\n",
    "\n",
    "            else:\n",
    "                max_salary = int(\"\".join([s for s in vacancy_salary.split('вЂ“')[1] if s.isdigit()]))\n",
    "                min_salary = int(\"\".join([s for s in vacancy_salary.split('вЂ“')[0] if s.isdigit()]))\n",
    "                currency = vacancy_salary.split()[-1]\n",
    "\n",
    "        vacancy_info['max_salary'] = max_salary\n",
    "        vacancy_info['min_salary'] = min_salary\n",
    "        vacancy_info['currency'] = currency\n",
    "\n",
    "        all_vacancies.append(vacancy_info)\n",
    "\n",
    "    params['page'] += 1\n",
    "    response = requests.get(main_url + '/search/vacancy', params=params, headers=headers)\n",
    "    print(len(all_vacancies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8699165",
   "metadata": {},
   "source": [
    "#### Момент с `user-Agent`\n",
    "В хед хантер (HH) если не передать юзер агент, то он нам даст 404 ошибку. Обязательно нужно передовать. Второй момент - идёт редирект по региону в котором мы живём. Это не является фильтром поиска вакансии. Это нормально. Это разгрузка нагрузки по серверам HH. \n",
    "\n",
    "https://hh.ru/search/vacancy?text=python&area=1 -ссылка на поиск по вакансии python\n",
    "\n",
    "Хед хантер ограничивает нас выдачью 2000 вакансий. Как бы мы к нему не обращались, хоть через апи, но больше 2000 вакансий хед хантер не выдаёт. Это особенность ресурса. Больше 2000 вакансий за один запрос не полуить!\n",
    "\n",
    "Собрать информацию о том сколько страниц с вакансиями. Это исследовать элемент и найти число со страницами `<span>40</span>` . Или исследовать элемент кнопку \"Дальше\". `<a class=\"bloko-button\" rel=\"nofollow\" data-qa=\"pager-next\" href=\"/search/vacancy?text=python&amp;area=1&amp;page=1&amp;hhtmFrom=vacancy_search_list\"><span>дальше</span></a>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb06311",
   "metadata": {},
   "source": [
    "##### Как взять URL для нужной вакансии\n",
    "Смотрим элемент через инструменты разработчика\n",
    "```\n",
    "<a class=\"serp-item__title\" data-qa=\"serp-item__title\" target=\"_blank\" href=\"https://hh.ru/analytics_source/vacancy/76390304?from=vacancy_search_list&amp;query=python&amp;requestId=1675239218829a88533135ef1c35229e&amp;totalVacancies=5151&amp;position=46&amp;source=vacancies\">Специалист в отдел мониторинга и автоматизации (VBA и Python)</a>\n",
    "```\n",
    "Берём тэг `'a'` с атрибутом `'data-qa': 'vacancy-serp__vacancy-title'` и берём у этого тега значение атрибута `href`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3359a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=vac.find_all('a', {'data-qa': 'vacancy-serp__vacancy-title'}, href=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea5c5ad",
   "metadata": {},
   "source": [
    "##### Точка входа \n",
    "https://hh.ru/vacancy/75538170?from=vacancy_search_list&query=python\n",
    "У нас есть ссылка со списком вакансий (20 шт на странице). В ссылке прописывается та вакансия, которую мы хотим в качестве параметра: `query=python`. \n",
    "\n",
    "https://hh.ru/search/vacancy?text=Python&from=suggest_post&salary=&area=1&ored_clusters=true&enable_snippets=true\n",
    "Ссылка на поиск по вакансии. Здесь также присутствует наша вакансия в виде параметра. `text=Python`\n",
    "\n",
    "Много разных параметров в ссылке но их не желательно удалять. Браузер так не делает. Лучше максимально подделоваться под браузер. \n",
    "\n",
    "Один из вариантов как можно указать ссылку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb08db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy = 'python'\n",
    "url = f'https://hh.ru/search/vacancy?text={vacancy}&from=suggest_post&salary=&area=1&ored_clusters=true&enable_snippets=true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b700cb",
   "metadata": {},
   "source": [
    "Ньюанс связанный с количеством страниц. на странице 50 вакансий, но мы получаем не больше 20. Переделали страницу и сделали динамическую выдачу данных. Остальные 30 страниц выдачи получаются с помощью динамики. \n",
    "\n",
    "В настройках страницы ставим показывать 20 страниц и не теряем динамического контента. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b38365f",
   "metadata": {},
   "source": [
    "Посмотреть куда мы пришли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4a31c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://spb.hh.ru/search/vacancy?search_field=name&search_field=company_name&search_field=description&search_field=name&search_field=company_name&search_field=description&search_field=name&search_field=company_name&search_field=description&search_field=name&search_field=company_name&search_field=description&text=python&text=python&text=python&text=python&page=4&hhtmFrom=vacancy_search_list&search_field=name&search_field=company_name&search_field=description&text=python'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.url "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1ddc9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Работа над парсером самостоятельная\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb754c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: webencodings in c:\\users\\777\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\777\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Installing collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81eccc6",
   "metadata": {},
   "source": [
    "Загружаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "281e5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a7610d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'user-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}\n",
    "vacancy = 'python'\n",
    "url = f'https://hh.ru/search/vacancy?text={vacancy}&from=suggest_post&salary=&area=1&ored_clusters=true&enable_snippets=true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62acea31",
   "metadata": {},
   "source": [
    "В хед хантер (HH) если не передать юзер агент в заголовках, то он нам даст 404 ошибку. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc238035",
   "metadata": {},
   "source": [
    "#### Get запрос \n",
    "Выполняем `get` запрос на сайт хедхантер по указанному выше `url` и указываем заголовки ` headers=headers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4af4f040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(url, headers=headers)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b355b68",
   "metadata": {},
   "source": [
    "#### DOM\n",
    "Получаем DOM . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a0ccde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b67bb",
   "metadata": {},
   "source": [
    "Ищем в инструментах разработчика необходимый нам элемент. Текст с профессией. \n",
    "\n",
    "`<a class=\"serp-item__title\" data-qa=\"serp-item__title\" target=\"_blank\" href=\"https://hh.ru/analytics_source/vacancy/68077706?from=vacancy_search_list&amp;query=Python&amp;requestId=1675242703327964ca472d0a0c76effa&amp;totalVacancies=5168&amp;position=0&amp;source=vacancies\">Python разработчик</a>`\n",
    "\n",
    "Разбираем DOM на запчасти. Собираем тег `<a>` с классом `class=\"serp-item__title`. Внутри этого тега у нас есть ссылка на вакансию и название специальности. сама вакансия. 2 единицы информации необходимой нам хронится в каждом элементе списка. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "431898c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacations = soup.find_all('a', {'class': 'serp-item__title'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1d969",
   "metadata": {},
   "source": [
    "У нас собирается список со всеми тегами `<a>` Посмотрим длину списка, она должна быть равной 20, т.к на странице у нас показано 20 вакансий. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d00a23a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vacations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0359e",
   "metadata": {},
   "source": [
    "Посмотрим на то что мы собрали, Посмотрим на самый первый собранный элемент. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "566b8fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"serp-item__title\" data-qa=\"serp-item__title\" href=\"https://hh.ru/vacancy/68077706?from=vacancy_search_list&amp;query=python\" target=\"_blank\">Python разработчик</a>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d6479",
   "metadata": {},
   "source": [
    "#### Собираем список со специальностями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a521ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy_list = []\n",
    "for el in vacations:\n",
    "    vacancy_list.append(el.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vacancy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae904e",
   "metadata": {},
   "source": [
    "#### Собираем список со ссылками на специальности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75be5701",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy_link = []\n",
    "for el in vacations:\n",
    "    vacancy_link.append(el['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "babe5deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://hh.ru/vacancy/68077706?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/76362476?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/71389643?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/68918046?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/72161518?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/73984561?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/76418401?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/69072132?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/66075789?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/71324858?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/76486172?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/47892571?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/47759634?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/73595103?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/71343276?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/68737867?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/75702430?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/75689151?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/76223564?from=vacancy_search_list&query=python',\n",
       " 'https://hh.ru/vacancy/76347722?from=vacancy_search_list&query=python']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vacancy_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bcac36",
   "metadata": {},
   "source": [
    "#### Создаю словарь, где ключ это название вакансии, значение - ссылка на вакансию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "672446c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vacancy_list) == len(vacancy_link):\n",
    "    vacansion_and_href_dict = dict(zip(vacancy_list, vacancy_link))\n",
    "else:\n",
    "    print('Списки не равны по длине')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f2c238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Backend python (стажер)': 'https://hh.ru/vacancy/76223564?from=vacancy_search_list&query=python',\n",
      " 'Build system Python developer': 'https://hh.ru/vacancy/76486868?from=vacancy_search_list&query=python',\n",
      " 'Data science': 'https://hh.ru/vacancy/75914060?from=vacancy_search_list&query=python',\n",
      " 'Junior Back-end Developer (Python)': 'https://hh.ru/vacancy/75702430?from=vacancy_search_list&query=python',\n",
      " 'Junior разработчик нейросетевых алгоритмов / Reinforcement Learning': 'https://hh.ru/vacancy/75081176?from=vacancy_search_list&query=python',\n",
      " 'Middle Python-разработчик': 'https://hh.ru/vacancy/75679088?from=vacancy_search_list&query=python',\n",
      " 'Python Devops (DSCore)': 'https://hh.ru/vacancy/71389643?from=vacancy_search_list&query=python',\n",
      " 'Python developer': 'https://hh.ru/vacancy/72424557?from=vacancy_search_list&query=python',\n",
      " 'Python разработчик': 'https://hh.ru/vacancy/75791573?from=vacancy_search_list&query=python',\n",
      " 'Python разработчик (удалённо)': 'https://hh.ru/vacancy/75955276?from=vacancy_search_list&query=python',\n",
      " 'Python разработчик / Junior DevOps инженер': 'https://hh.ru/vacancy/76347722?from=vacancy_search_list&query=python',\n",
      " 'Python-разработчик': 'https://hh.ru/vacancy/76469323?from=vacancy_search_list&query=python',\n",
      " 'Python-разработчик (junior)': 'https://hh.ru/vacancy/75689151?from=vacancy_search_list&query=python',\n",
      " 'Senior Python разработчик': 'https://hh.ru/vacancy/68918046?from=vacancy_search_list&query=python',\n",
      " 'Программист Python': 'https://hh.ru/vacancy/75773592?from=vacancy_search_list&query=python',\n",
      " 'Программист Python/JavaScript': 'https://hh.ru/vacancy/76104420?from=vacancy_search_list&query=python',\n",
      " 'Разработчик Python': 'https://hh.ru/vacancy/75862579?from=vacancy_search_list&query=python',\n",
      " 'Тестировщик ПО (Python)': 'https://hh.ru/vacancy/73037104?from=vacancy_search_list&query=python'}\n"
     ]
    }
   ],
   "source": [
    "pprint(vacansion_and_href_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f609ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d201ed42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2257ded9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d770e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кем хотите работать?лор\n",
      "Найдено 20 вакансий\n",
      "{'Администратор клиники': 'https://hh.ru/vacancy/76514694?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Администратор медицинского центра': 'https://hh.ru/vacancy/75679094?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Врач - оториноларинголог детский': 'https://hh.ru/vacancy/74386211?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Врач ЛОР': 'https://hh.ru/vacancy/76073952?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Врач онколог отделения опухолей головы и шеи': 'https://hh.ru/vacancy/75632689?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Врач оториноларинголог (м. Щукинская)': 'https://hh.ru/vacancy/76480334?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Врач-оториноларинголог': 'https://hh.ru/vacancy/76245567?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Врач-оториноларинголог (ЛОР)': 'https://hh.ru/vacancy/76160993?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Врач-оториноларинголог (ЛОР, м. Полянка)': 'https://hh.ru/vacancy/75647422?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Врач-оториноларинголог (м. Красногвардейская)': 'https://hh.ru/vacancy/74097818?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Врач-оториноларинголог (м. Марьина Роща)': 'https://hh.ru/vacancy/76089422?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Лор-врач': 'https://hh.ru/vacancy/74141766?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80',\n",
      " 'Специалист ЛФК': 'https://hh.ru/vacancy/75933728?from=vacancy_search_list&query=%D0%BB%D0%BE%D1%80'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "headers = {'user-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}\n",
    "vacancy = input('Кем хотите работать?')\n",
    "url = f'https://hh.ru/search/vacancy?text={vacancy}&from=suggest_post&salary=&area=1&ored_clusters=true&enable_snippets=true'\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "vacations = soup.find_all('a', {'class': 'serp-item__title'})\n",
    "print(f'Найдено {len(vacations)} вакансий')\n",
    "\n",
    "vacs_link = []\n",
    "vacs_list = []\n",
    "for el in vacations:\n",
    "    vacs_list.append(el.text)\n",
    "    vacs_link.append(el['href'])\n",
    "\n",
    "if len(vacs_list) == len(vacs_link):\n",
    "    vacansion_and_href_dict = dict(zip(vacs_list, vacs_link))\n",
    "else:\n",
    "    print('Списки не равны по длине')\n",
    "    \n",
    "pprint(vacansion_and_href_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64477e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737cbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744465d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d7752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea3f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f102b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ffc20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb2bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29ea8b6b",
   "metadata": {},
   "source": [
    "### Пример решения домашнего задания\n",
    "https://github.com/Androkotey\n",
    "\n",
    "Простое и хорошее решение строковоми методами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0577007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите вакансию для поиска: python\n",
      "Page 0 is being processed...\n",
      "Page 0 done\n",
      "Page 1 is being processed...\n",
      "Page 1 done\n",
      "Page 2 is being processed...\n",
      "Page 2 done\n",
      "Page 3 is being processed...\n",
      "Page 3 done\n",
      "Page 4 is being processed...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'getText'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m vacancy_link \u001b[38;5;241m=\u001b[39m vacancy_title[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m][: vacancy_title[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     58\u001b[0m vacancy_salary \u001b[38;5;241m=\u001b[39m salary_extraction(vacancy\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbloko-header-section-3\u001b[39m\u001b[38;5;124m'\u001b[39m]}))\n\u001b[1;32m---> 59\u001b[0m vacancy_employer \u001b[38;5;241m=\u001b[39m vacancy\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata-qa\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvacancy-serp__vacancy-employer\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mgetText()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     60\u001b[0m vacancy_address \u001b[38;5;241m=\u001b[39m vacancy\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata-qa\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvacancy-serp__vacancy-address\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mgetText()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     62\u001b[0m vacancy_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m vacancy_name\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'getText'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Функция для зарплаты\n",
    "def salary_extraction(vacancy_salary):\n",
    "    salary_dict = {'min': None, 'max': None, 'cur': None}\n",
    "\n",
    "    if vacancy_salary:\n",
    "        # делится всё по этому символу `' – '`?\n",
    "        # удаляются пробелы и получаем общую структуру\n",
    "        raw_salary = vacancy_salary.getText().replace(' – ', ' ').replace(' ', '').split()\n",
    "        # Если в списке есть ДО\n",
    "        if raw_salary[0] == 'до':\n",
    "            # до 380 000 руб.\n",
    "            # тогда сэлери макс берётся из первого элемента списка\n",
    "            salary_dict['max'] = int(raw_salary[1])\n",
    "        elif raw_salary[0] == 'от':\n",
    "            # от 50 000 руб.\n",
    "            # берём минимальную зарплату\n",
    "            salary_dict['min'] = int(raw_salary[1])\n",
    "        else:\n",
    "            # 50 000 – 100 000 руб.\n",
    "            salary_dict['min'] = int(raw_salary[0])\n",
    "            salary_dict['max'] = int(raw_salary[1])\n",
    "        salary_dict['cur'] = raw_salary[2].replace('.', '')\n",
    "\n",
    "    return salary_dict\n",
    "\n",
    "\n",
    "main_url = 'https://spb.hh.ru/'\n",
    "\n",
    "params = {'search_field': ['name', 'company_name', 'description']}\n",
    "params['text'] = input('Введите вакансию для поиска: ')\n",
    "max_page = 99999  # не вижу смысла в ограничении количества страниц\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.67 Safari/537.36'}\n",
    "page_link = '/search/vacancy'\n",
    "vacancies = []\n",
    "i = 0\n",
    "\n",
    "# Снаружи внешний цикл\n",
    "# который также завязан на следующей странице\n",
    "# if not next_page\n",
    "\n",
    "while True:\n",
    "    response = requests.get(main_url + page_link,\n",
    "                            params=params,\n",
    "                            headers=headers)\n",
    "    html = response.text\n",
    "    soup = bs(html, 'html.parser')\n",
    "    # собираются вакансии\n",
    "    vacancies_soup = soup.find_all('div', {'class': ['vacancy-serp-item-body__main-info']})\n",
    "\n",
    "    print(f'Page {i} is being processed...')\n",
    "    for vacancy in vacancies_soup:\n",
    "\n",
    "        vacancy_data = {'website': 'hh.ru'}\n",
    "\n",
    "        vacancy_title = vacancy.find('a')\n",
    "\n",
    "        vacancy_name = vacancy_title.getText()\n",
    "        vacancy_link = vacancy_title['href'][: vacancy_title['href'].index('?')]\n",
    "        vacancy_salary = salary_extraction(vacancy.find('span', {'class': ['bloko-header-section-3']}))\n",
    "        vacancy_employer = vacancy.find('a', {'data-qa': 'vacancy-serp__vacancy-employer'}).getText().replace('\\xa0', ' ')\n",
    "        vacancy_address = vacancy.find('div', {'data-qa': 'vacancy-serp__vacancy-address'}).getText().replace('\\xa0', ' ')\n",
    "\n",
    "        vacancy_data['name'] = vacancy_name\n",
    "        vacancy_data['link'] = vacancy_link\n",
    "        vacancy_data['salary_min'] = vacancy_salary['min']\n",
    "        vacancy_data['salary_max'] = vacancy_salary['max']\n",
    "        vacancy_data['salary_currency'] = vacancy_salary['cur']\n",
    "        vacancy_data['employer'] = vacancy_employer\n",
    "        vacancy_data['address'] = vacancy_address\n",
    "\n",
    "        vacancies.append(vacancy_data)\n",
    "# проверяем, если мы не нашли кнопку следующая или достигли максимальной страницы\n",
    "# по параметру max_page можно ограничить число страниц для выдачи. \n",
    "    next_page = soup.find('a', {'data-qa': 'pager-next'})\n",
    "    if not next_page or (i == max_page):\n",
    "        break\n",
    "    page_link = next_page['href']\n",
    "    print(f'Page {i} done')\n",
    "    i += 1\n",
    "\n",
    "vacancies_data = pd.DataFrame(data=vacancies)\n",
    "prefix = '_'.join(params['text'].split())\n",
    "vacancies_data.to_csv(f'hh_vacancies_{prefix}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d9cd9",
   "metadata": {},
   "source": [
    "##  Пример решения домашнего задания\n",
    "https://github.com/belkanov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4339825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 13:18:28 | INFO     | job_scraper | --- START\n",
      "2023-02-01 13:18:28 | INFO     | job_scraper | Parse page #1\n",
      "2023-02-01 13:18:30 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:18:30 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:18:30 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:18:31 | INFO     | job_scraper | Parse page #2\n",
      "2023-02-01 13:18:32 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:18:32 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:18:32 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:18:33 | INFO     | job_scraper | Parse page #3\n",
      "2023-02-01 13:18:35 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:18:35 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:18:35 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:18:36 | INFO     | job_scraper | Parse page #4\n",
      "2023-02-01 13:18:38 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:18:38 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:18:38 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:18:39 | INFO     | job_scraper | Parse page #5\n",
      "2023-02-01 13:18:40 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:18:40 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:18:40 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:18:41 | INFO     | job_scraper | Parse page #6\n",
      "2023-02-01 13:18:43 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:18:43 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:18:43 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:18:44 | INFO     | job_scraper | Parse page #7\n",
      "2023-02-01 13:18:46 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:18:46 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:18:46 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:18:47 | INFO     | job_scraper | Parse page #8\n",
      "2023-02-01 13:19:10 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:10 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:10 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:11 | INFO     | job_scraper | Parse page #9\n",
      "2023-02-01 13:19:13 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:13 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:13 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:14 | INFO     | job_scraper | Parse page #10\n",
      "2023-02-01 13:19:16 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:16 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:16 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:17 | INFO     | job_scraper | Parse page #11\n",
      "2023-02-01 13:19:19 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:19 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:19 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:20 | INFO     | job_scraper | Parse page #12\n",
      "2023-02-01 13:19:21 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:21 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:21 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:22 | INFO     | job_scraper | Parse page #13\n",
      "2023-02-01 13:19:24 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:24 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:24 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:25 | INFO     | job_scraper | Parse page #14\n",
      "2023-02-01 13:19:27 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:27 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:27 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:28 | INFO     | job_scraper | Parse page #15\n",
      "2023-02-01 13:19:29 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:29 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:29 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:30 | INFO     | job_scraper | Parse page #16\n",
      "2023-02-01 13:19:33 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:33 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:33 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:34 | INFO     | job_scraper | Parse page #17\n",
      "2023-02-01 13:19:35 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:35 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:35 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:36 | INFO     | job_scraper | Parse page #18\n",
      "2023-02-01 13:19:41 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:41 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:41 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:42 | INFO     | job_scraper | Parse page #19\n",
      "2023-02-01 13:19:44 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:44 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:44 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:45 | INFO     | job_scraper | Parse page #20\n",
      "2023-02-01 13:19:46 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:46 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:46 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:47 | INFO     | job_scraper | Parse page #21\n",
      "2023-02-01 13:19:49 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:49 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:49 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:50 | INFO     | job_scraper | Parse page #22\n",
      "2023-02-01 13:19:52 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:52 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:52 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:53 | INFO     | job_scraper | Parse page #23\n",
      "2023-02-01 13:19:55 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:55 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:55 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:19:56 | INFO     | job_scraper | Parse page #24\n",
      "2023-02-01 13:19:59 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:19:59 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:19:59 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:00 | INFO     | job_scraper | Parse page #25\n",
      "2023-02-01 13:20:03 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:03 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:03 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:04 | INFO     | job_scraper | Parse page #26\n",
      "2023-02-01 13:20:05 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:05 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:05 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:06 | INFO     | job_scraper | Parse page #27\n",
      "2023-02-01 13:20:08 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:08 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:08 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:09 | INFO     | job_scraper | Parse page #28\n",
      "2023-02-01 13:20:11 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:11 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:11 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:12 | INFO     | job_scraper | Parse page #29\n",
      "2023-02-01 13:20:14 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:14 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:14 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:15 | INFO     | job_scraper | Parse page #30\n",
      "2023-02-01 13:20:17 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:17 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:17 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:18 | INFO     | job_scraper | Parse page #31\n",
      "2023-02-01 13:20:19 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 13:20:19 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:19 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:20 | INFO     | job_scraper | Parse page #32\n",
      "2023-02-01 13:20:22 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:22 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:22 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:23 | INFO     | job_scraper | Parse page #33\n",
      "2023-02-01 13:20:25 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:25 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:25 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:26 | INFO     | job_scraper | Parse page #34\n",
      "2023-02-01 13:20:28 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:28 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:28 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:29 | INFO     | job_scraper | Parse page #35\n",
      "2023-02-01 13:20:30 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:30 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:30 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:31 | INFO     | job_scraper | Parse page #36\n",
      "2023-02-01 13:20:32 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:32 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:32 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:33 | INFO     | job_scraper | Parse page #37\n",
      "2023-02-01 13:20:35 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:35 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:35 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:36 | INFO     | job_scraper | Parse page #38\n",
      "2023-02-01 13:20:38 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:38 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:38 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:39 | INFO     | job_scraper | Parse page #39\n",
      "2023-02-01 13:20:41 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:41 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:41 | INFO     | job_scraper | Нашел.\n",
      "2023-02-01 13:20:42 | INFO     | job_scraper | Parse page #40\n",
      "2023-02-01 13:20:44 | INFO     | job_scraper | Нашел 0 вакансий. Обрабатываю...\n",
      "2023-02-01 13:20:44 | INFO     | job_scraper | Ищу следующую страницу...\n",
      "2023-02-01 13:20:44 | INFO     | job_scraper | Видимо это последняя =) Всего обработано 40 страниц\n",
      "2023-02-01 13:20:44 | INFO     | job_scraper | --- END\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы получаем должность)\n",
    "с сайтов HH(обязательно) и/или Superjob(по желанию).\n",
    "Приложение должно анализировать несколько страниц сайта (также вводим через input или аргументы).\n",
    "Получившийся список должен содержать в себе минимум:\n",
    "Наименование вакансии.\n",
    "Предлагаемую зарплату (разносим в три поля: минимальная и максимальная и валюта. цифры преобразуем к цифрам).\n",
    "Ссылку на саму вакансию.\n",
    "Сайт, откуда собрана вакансия.\n",
    "По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение).\n",
    "Структура должна быть одинаковая для вакансий с обоих сайтов.\n",
    "Общий результат можно вывести с помощью dataFrame через pandas.\n",
    "Сохраните в json либо csv.\n",
    "\"\"\"\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from collections import namedtuple\n",
    "import logging\n",
    "import json\n",
    "\n",
    "RE_SALARY = re.compile(r'(?:\\d+\\s*){1,}')\n",
    "RE_CURRENCY = re.compile(r'\\D+')\n",
    "MAIN_URL = 'https://hh.ru'\n",
    "VACANCY_URL = f'{MAIN_URL}/search/vacancy'\n",
    "HEADERS = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.67 Safari/537.36'\n",
    "}\n",
    "vacancy_name = 'python'\n",
    "PARAMS = {\n",
    "    'text': vacancy_name\n",
    "}\n",
    "\n",
    "Salary = namedtuple('Salary', (\n",
    "    'min',\n",
    "    'max',\n",
    "    'currency'\n",
    "))\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger('job_scraper')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# если включить - можно увидеть редиректы\n",
    "# requests_log = logging.getLogger(\"urllib3\")\n",
    "# requests_log.setLevel(logging.DEBUG)\n",
    "# requests_log.propagate = True\n",
    "\n",
    "\n",
    "def get_response(url, headers, params=None):\n",
    "    timeouts = (5, 5)  # conn, read\n",
    "    response = requests.get(url,\n",
    "                            headers=headers,\n",
    "                            params=params,\n",
    "                            timeout=timeouts)\n",
    "    if response.ok:\n",
    "        # на случай редиректа hh.ru -> rostov.hh.ru\n",
    "        splitted_response_url = response.url.split('/')\n",
    "        new_main_url = f'{splitted_response_url[0]}//{splitted_response_url[2]}'\n",
    "        return response, new_main_url\n",
    "\n",
    "# Отдельная функция, которая преобразует полученные значения зарплаты к числовому типу данных\n",
    "def get_int(re_match):\n",
    "    return int(re_match.group().replace(' ', ''))\n",
    "\n",
    "# Проверка зарплатных полей на None значения и обработка зарплат\n",
    "def get_salary(tag):\n",
    "    if tag is None:\n",
    "        return Salary(None, None, None)\n",
    "\n",
    "    text = clear_tag_text(tag)\n",
    "    # получалось неплохо через всякие сплиты/слайсы/джоины,\n",
    "    # но потом пришли 'бел. руб.' и все сломалось =)\n",
    "    # поэтому регулярки\n",
    "    if 'от' in text:\n",
    "        re_salary = RE_SALARY.search(text)\n",
    "        salary = get_int(re_salary)\n",
    "        re_currency = RE_CURRENCY.search(text, re_salary.end())\n",
    "        return Salary(salary, None, re_currency.group())\n",
    "    elif 'до' in text:\n",
    "        re_salary = RE_SALARY.search(text)\n",
    "        salary = get_int(re_salary)\n",
    "        re_currency = RE_CURRENCY.search(text, re_salary.end())\n",
    "        return Salary(None, salary, re_currency.group())\n",
    "    else:\n",
    "        re_min_salary = RE_SALARY.search(text)\n",
    "        min_salary = get_int(re_min_salary)\n",
    "        re_max_salary = RE_SALARY.search(text, re_min_salary.end())\n",
    "        max_salary = get_int(re_max_salary)\n",
    "        re_currency = RE_CURRENCY.search(text, re_max_salary.end())\n",
    "        return Salary(min_salary, max_salary, re_currency.group())\n",
    "    \n",
    "    \n",
    "# Функция удаляет символы переноса строчек \n",
    "\n",
    "def clear_tag_text(tag):\n",
    "    text = tag.getText()\n",
    "    text = text.replace('\\n', '')\n",
    "    # внезапно вылезло много пробелов\n",
    "    splitted = [word for word in text.split() if word]\n",
    "    text = ' '.join(splitted)\n",
    "    return text\n",
    "\n",
    "\n",
    "def parse_vacancy_link(tag):\n",
    "    link = tag.get('href')\n",
    "    return f'{MAIN_URL}{link}'\n",
    "\n",
    "\n",
    "def save_to_file(data, file_name):\n",
    "    with open(file_name, 'w', encoding='utf8') as f:\n",
    "        f.write(data)\n",
    "\n",
    "# Сам алгоритм перебора данных. \n",
    "# делаем запрос по ссылке\n",
    "# получаем вакансии\n",
    "\n",
    "# Функция с циклом которая перебирает вакансии на одной странице.\n",
    "\n",
    "def parse_response(response, main_url):\n",
    "    vacancies_info = []\n",
    "\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    anchor = soup.find('div', {'class': 'vacancy-serp-content'})\n",
    "\n",
    "    vacancy_results = anchor.find('div', {'data-qa': 'vacancy-serp__results'})\n",
    "    # здесь получаются наши вакансии через find_all()\n",
    "    vacancies = vacancy_results.find_all('div', {'class': 'vacancy-serp-item'})\n",
    "    logger.info('Нашел %d вакансий. Обрабатываю...', len(vacancies))\n",
    "    # начинаем итеррироваться по всему списку, \n",
    "    # заходя внутрь и получая данные по каждой вакансии\n",
    "    for vacancy in vacancies:\n",
    "        title_tag = vacancy.find('a', {'data-qa': 'vacancy-serp__vacancy-title'})\n",
    "        salary_tag = vacancy.find('span', {'data-qa': 'vacancy-serp__vacancy-compensation'})\n",
    "        \n",
    "        # словарик со всей необходимой нам информацией. \n",
    "        # для каждого данного возвращается функция и всё нам \"причёсывает\"\n",
    "        vacancy_info = {\n",
    "            'name': clear_tag_text(title_tag),\n",
    "            'salary': get_salary(salary_tag),\n",
    "            'link': title_tag.get('href'),\n",
    "            'site': main_url,\n",
    "        }\n",
    "        vacancies_info.append(vacancy_info)\n",
    "\n",
    "    return vacancies_info, anchor\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_vacancies = []\n",
    "\n",
    "    page_cnt = 1\n",
    "    url = VACANCY_URL\n",
    "    headers = HEADERS\n",
    "    params = PARAMS\n",
    "    \n",
    "    # Второй главный цикл, который перебирает страницы, \n",
    "    # обрабатывая каждую страницу с помощью функций\n",
    "    while True:\n",
    "        logger.info('Parse page #%d', page_cnt)\n",
    "        response, main_url = get_response(url, headers=headers, params=params)\n",
    "        # если ответ не пришёл\n",
    "        if not response:\n",
    "            logger.error('NO response from %s', url)\n",
    "            raise SystemExit(1)\n",
    "        \n",
    "        try:\n",
    "            vacancies_info, anchor = parse_response(response, main_url)\n",
    "        except ValueError as e:\n",
    "            logger.exception(e)\n",
    "            save_to_file(response.text, 'error_response.html')\n",
    "            raise SystemExit(1)\n",
    "\n",
    "        all_vacancies.extend(vacancies_info)\n",
    "\n",
    "        logger.info('Ищу следующую страницу...')\n",
    "        next_link = anchor.find('a', {'data-qa': 'pager-next'})\n",
    "        # переход по страницам как осуществляется? \n",
    "        # Ищем кнопку следующая на странице и ссылку которая под этой кнопкой бывает\n",
    "        # извлекаем ссылку на следующую страницу\n",
    "        \n",
    "        # дальше по этой ссылке снова выполняем get-запрос.w\n",
    "        if next_link:\n",
    "            logger.info('Нашел.')\n",
    "            url = f'{main_url}{next_link.get(\"href\")}'\n",
    "            params = None\n",
    "            page_cnt += 1\n",
    "            sleep(1)  # не будем спамить запросами\n",
    "        else:\n",
    "            logger.info('Видимо это последняя =) Всего обработано %d страниц',\n",
    "                        page_cnt)\n",
    "            break\n",
    "\n",
    "    with open('vacancies.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_vacancies, f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger.info('--- START')\n",
    "    main()\n",
    "    logger.info('--- END')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6471027",
   "metadata": {},
   "source": [
    "## Пример парсера, но изменилась структура сайта и парсер уже не отрабатывает "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871b7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "headers = {'user-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 9_1 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Version/9.0 Mobile/13B137 Safari/601.1'}\n",
    "url = 'https://msk.hh.ru/search/vacancy'\n",
    "\n",
    "def find_vacations(vac_name):\n",
    "    ### Понимаю, что код с двумя вложенными циклами трудно назвать оптимальным, \n",
    "    ### но на что-то лучшее, к сожалению, не хватило времени. Очень большие выдачи считает\n",
    "    ### довольно долго (5-7 мин)\n",
    "    ### Максимальное число ответов в выдаче, независимо от их реального числа, - не более 2000. Видимо, опять сайт режет?\n",
    "    ### Добавил в выдачу еще и работодателя, хотя этого не было в задании.\n",
    "    params = {'text' : vac_name}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    c = soup.find('h1', {'data-qa': 'bloko-header-3'})\n",
    "    x = re.findall('[0-9]+', c.get_text())\n",
    "    number = int(''.join(map(str, x)))\n",
    "    number = int(number/20) #Нашел на странице строчку, где указано общее число запросов в выдаче, вынул оттуда это число, разделил на 20 (это значение числа вакансий #на странице установил принудительно ниже) и так нашел общее число страниц в выдаче\n",
    "    \n",
    "    lst = []\n",
    "    page  = 0\n",
    "    while page <= number:\n",
    "        params = {'text' : vac_name, 'page' : page, 'items_on_page' : 20}\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        vacations = soup.find_all('div', {'class': 'vacancy-serp-item'})\n",
    "        for vac in vacations:\n",
    "            temp = {}\n",
    "            a=vac.find_all('span', {'class': 'g-user-content'})\n",
    "            for elt in a:\n",
    "                temp['Должность'] = elt.text\n",
    "            b=vac.find_all('span', {'data-qa': 'vacancy-serp__vacancy-compensation'})\n",
    "            for elt in b:\n",
    "                temp['Зарплата'] = elt.text.replace('\\\\u202f','')\n",
    "            c=vac.find_all('a', {'data-qa': 'vacancy-serp__vacancy-employer'}) \n",
    "            for elt in c:\n",
    "                temp['Работодатель'] = elt.text\n",
    "            d=vac.find_all('a', {'data-qa': 'vacancy-serp__vacancy-title'}, href=True) \n",
    "            for elt in d:\n",
    "                temp['Ссылка на вакансию'] = elt['href'] \n",
    "            lst.append(temp)\n",
    "            page += 1\n",
    "    x = pd.DataFrame(lst)\n",
    "\n",
    "    x['Валюта'] = x['Зарплата'].replace('[0-9–дот]','',regex=True)\n",
    "    x['Мин.зарплата'] = np.select([x['Зарплата'].str.contains('от',na=False), x['Зарплата'].str.contains('до',na=False), x['Зарплата'].str.contains('–',na=False)],\n",
    "    [x['Зарплата'].replace('[^\\\\d]','',regex=True),0, x['Зарплата'].replace('–.*','',regex=True)])\n",
    "\n",
    "    x['Макс.зарплата'] = np.select([x['Зарплата'].str.contains('от',na=False), x['Зарплата'].str.contains('до',na=False), x['Зарплата'].str.contains('–',na=False)],\n",
    "    [0, x['Зарплата'].replace('[^\\\\d]','',regex=True), x['Зарплата'].replace('.*–','',regex=True).replace('[^\\\\d]','',regex=True)])\n",
    "    x.fillna('не указана', inplace=True)\n",
    "    x.drop('Зарплата',axis=1,inplace=True)\n",
    "    x = x.reindex(columns=['Должность', 'Работодатель', 'Мин.зарплата', 'Макс.зарплата', 'Валюта', 'Ссылка на вакансию'])\n",
    "    x[['Мин.зарплата', 'Макс.зарплата']] = x[['Мин.зарплата', 'Макс.зарплата']].astype('int')\n",
    "    x.index +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27784a",
   "metadata": {},
   "source": [
    "# Собственное решение. Работа над решением\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "79a716ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кем хотите работать?механик по лифтам\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "headers = {'user-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}\n",
    "vacancy = input('Кем хотите работать?')\n",
    "url = f'https://hh.ru/search/vacancy?text={vacancy}&from=suggest_post&salary=&area=1&ored_clusters=true&enable_snippets=true'\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df17b0c",
   "metadata": {},
   "source": [
    "Сделал DOM и поместил в переменную soup. Дальше с помощью инструментов разработчика смотрю на сайте контейнер, в котором находится всё что мне необходимо. Выделяю блок со всеми вакансиями со страницы.\n",
    "`<div class=\"vacancy-serp-content\">` - это тег который содержит вложенные теги с каждой вакансией. Предположим это будет стартовая точка, откуда я пойду спускаться вниз по детям. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c100bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = soup.find('div', {'class': 'vacancy-serp-content'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a48df",
   "metadata": {},
   "source": [
    "Теперь работая с анкером в который поместил контейнер со всеми объявлениями, попробую найти контейнер под каждое объявление. В инструментах разработчика начинаю смотреть детей тега `<div class=\"vacancy-serp-content\">`.  Я хочу найти все контейнеры, которые будут содержать информацию по каждой вакансии на странице. `<div class=\"serp-item\" data-qa=\"vacancy-serp__vacancy vacancy-serp__vacancy_premium\">` - это контейнер содержащий вакансию и её описание. Ищу все такие теги по классу `<div class=\"serp-item\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "80f084bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacansions_all_info = anchor.find_all('div', {'class': 'serp-item'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735265bb",
   "metadata": {},
   "source": [
    "Т.к. искал все вхождения `<div class=\"serp-item\"` в результате должен получиться список.\n",
    "Проверяю длину получившегося списка. Если длина равна 20 - это отличный результат, так как мы собираем по 20 вакансий со страницы. И теперь с каждым элементом этого списка можно работать, собрав нужную нам информацию. Циклом пройтись по этому списку например."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "92c350a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vacansions_all_info) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d114777b",
   "metadata": {},
   "source": [
    "Снова захожу в инструменты разработчика и начинаю анализировать содержимое контейнера с вакансией `<div class=\"serp-item\"`\n",
    "Ищем детей этого контейнера. Для начала хочу обработать одно объявление. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b7aa333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacansion_info = vacansions_all_info[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db74d2",
   "metadata": {},
   "source": [
    "При анализе кода в инструменте разработчика нахожу участок кода, содержащий нужную информацию `<div class=\"vacancy-serp-item-body\">` Посмотрим что там есть...  Есть тэг с ссылкой на вакансию и названием вакансии `<a class=\"serp-item__title\" data-qa=\"serp-item__title\" target=\"_blank\" href=\"https://hh.ru/vacancy/68077706?from=vacancy_search_list&amp;query=python\">Python разработчик</a>`. Также в этом контейнере есть тэг с роботодателем: `<a data-qa=\"vacancy-serp__vacancy-employer\" class=\"bloko-link bloko-link_kind-tertiary\" href=\"/employer/2136954?hhtmFrom=vacancy_search_list\">Домклик</a>`. собираем соответственно эту информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8c47b",
   "metadata": {},
   "source": [
    "Получаю название вакансии, которое содержится в теге `<a class=\"serp-item__title\" data-qa=\"serp-item__title\" target=\"_blank\" href=\"https://hh.ru/vacancy/68077706?from=vacancy_search_list&amp;query=python\">Python разработчик</a>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b37ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacansion_name = vacansion_info.find('a',{ 'class':'serp-item__title'}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2fb4eebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Сантехник / Монтажник систем отопления'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacansion_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e663186e",
   "metadata": {},
   "source": [
    "Получаю ссылку на вакансию, которая также содержится в теге в атрибуте href  `<a class=\"serp-item__title\" data-qa=\"serp-item__title\" target=\"_blank\" href=\"https://hh.ru/vacancy/68077706?from=vacancy_search_list&amp;query=python\">Python разработчик</a>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "86e4f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacansion_link = vacansion_info.find('a',{ 'class':'serp-item__title'})['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d7dc7e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://hh.ru/vacancy/76568749?query=%D1%81%D0%B0%D0%BD%D1%82%D0%B5%D1%85%D0%BD%D0%B8%D0%BA'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacansion_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89331da4",
   "metadata": {},
   "source": [
    "Получаю название организаци. которая разместила объявление о вакансии. Эти данные находим в теге `<a data-qa=\"vacancy-serp__vacancy-employer\" class=\"bloko-link bloko-link_kind-tertiary\" href=\"/employer/2136954?hhtmFrom=vacancy_search_list\">Домклик</a>`, откуда надо взять текст. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4a84328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancion_organization = vacansion_info.find('a',{ 'class':'bloko-link'}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancion_organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d719a7d1",
   "metadata": {},
   "source": [
    "Зарплата указана не на всех вакансиях, Но там где она указана попробуем её собрать. В инструменте разработчика смотрим где расположены данные по зарплатам `<span data-qa=\"vacancy-serp__vacancy-compensation\" class=\"bloko-header-section-3\">100 000 – 250 000 <!-- -->руб.</span>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "84ed8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vacancion_money =  vacansion_info.find('span',{ 'data-qa':'vacancy-serp__vacancy-compensation'}).text\n",
    "except:\n",
    "     vacancion_money = 'зарплата не указана'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73d63947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50\\u202f000 – 50\\u202f000 руб.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancion_money"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500ee351",
   "metadata": {},
   "source": [
    "а теперь в цикле собрать данных и вывести пользователю. промежуточный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "73b02878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " вакансия: Наладчик по лифтам\n",
      " организация: ООО Мегаполис\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76583048?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: от 80 000 руб. \n",
      " *******\n",
      " вакансия: Механик по лифтам\n",
      " организация: ООО Технолифт Сервис\n",
      " ссылка на вакансию: https://hh.ru/vacancy/75892171?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: от 130 000 руб. \n",
      " *******\n",
      " вакансия: Электромеханик по лифтам\n",
      " организация: ООО ТСК АРКС\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76396321?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 60 000 – 60 000 руб. \n",
      " *******\n",
      " вакансия: Электромеханик по лифтам\n",
      " организация: ООО Подъем\n",
      " ссылка на вакансию: https://hh.ru/vacancy/75675907?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 70 000 – 120 000 руб. \n",
      " *******\n",
      " вакансия: Механик (мастер - наладчик) лифтового оборудования\n",
      " организация: Группа компаний Заслон (ООО Заслон)\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76220433?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: от 70 000 руб. \n",
      " *******\n",
      " вакансия: Инженер-механик\n",
      " организация: ООО Киевская Площадь\n",
      " ссылка на вакансию: https://hh.ru/vacancy/71270008?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 77 000 – 77 000 руб. \n",
      " *******\n",
      " вакансия: Инженер-наладчик\n",
      " организация: METEOR Lift\n",
      " ссылка на вакансию: https://hh.ru/vacancy/71201828?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: зарплата не указана \n",
      " *******\n",
      " вакансия: Механик-наладчик эскалаторного оборудования\n",
      " организация: Московский аэропорт Домодедово\n",
      " ссылка на вакансию: https://hh.ru/vacancy/55008509?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 120 000 – 150 000 руб. \n",
      " *******\n",
      " вакансия: Инженер в отдел главного механика\n",
      " организация: Гохран России\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76482397?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 75 000 – 75 000 руб. \n",
      " *******\n",
      " вакансия: Инженер по ремонту грузовых подъёмников\n",
      " организация: ООО ПАСТЕР-ХОЛДИНГ-М\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76295500?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 65 000 – 110 000 руб. \n",
      " *******\n",
      " вакансия: Главный механик АХО\n",
      " организация: Спецсвязь России (ГЦСС) ФГУП\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76232697?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 60 000 – 60 000 руб. \n",
      " *******\n",
      " вакансия: Электромеханик по лифтам и эскалаторам\n",
      " организация: ООО ЭКСПРЕСС\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76238529?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 38 000 – 40 000 руб. \n",
      " *******\n",
      " вакансия: Электромеханик по лифтам в аварийную службу\n",
      " организация: ООО ТСК АРКС\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76095705?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 120 000 – 120 000 руб. \n",
      " *******\n",
      " вакансия: Электромеханик по лифтам\n",
      " организация: Траст-Лифт\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76079971?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: от 70 000 руб. \n",
      " *******\n",
      " вакансия: Инженер по эксплуатации зданий/ Главный механик по эксплуатации\n",
      " организация: ООО УК «МНПО «СПЕКТР»\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76221622?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: от 101 000 руб. \n",
      " *******\n",
      " вакансия: Инженер сервисной службы (Сервисный инженер)\n",
      " организация: АО Промстройконтракт\n",
      " ссылка на вакансию: https://hh.ru/vacancy/74353833?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: от 70 000 руб. \n",
      " *******\n",
      " вакансия: Помощник/ассистент менеджера по продажам (инженер по подбору оборудования)\n",
      " организация: ООО РЕВАТОР\n",
      " ссылка на вакансию: https://hh.ru/vacancy/75792316?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 60 000 – 90 000 руб. \n",
      " *******\n",
      " вакансия: Инженер-механик по лифтам, эскалаторам и подъемникам\n",
      " организация: ЕВРОПЕЙСКИЙ, Торгово-Развлекательный центр\n",
      " ссылка на вакансию: https://hh.ru/vacancy/66831193?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: от 80 000 руб. \n",
      " *******\n",
      " вакансия: Государственный инспектор надзор за лифтами (инженер-механик)\n",
      " организация: Центральное управление Федеральной службы по экологическому, технологическому и атомному надзору\n",
      " ссылка на вакансию: https://hh.ru/vacancy/72521749?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: 40 000 – 50 000 руб. \n",
      " *******\n",
      " вакансия: Главный эксперт в отдел главного механика\n",
      " организация: АО Гринатом\n",
      " ссылка на вакансию: https://hh.ru/vacancy/76089750?from=vacancy_search_list&query=%D0%BC%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA+%D0%BF%D0%BE+%D0%BB%D0%B8%D1%84%D1%82%D0%B0%D0%BC\n",
      " зарплата: зарплата не указана \n",
      " *******\n"
     ]
    }
   ],
   "source": [
    "for vacansion_info in vacansions_all_info:\n",
    "    vacansion_name = vacansion_info.find('a',{ 'class':'serp-item__title'}).get_text()\n",
    "    vacansion_link = vacansion_info.find('a',{ 'class':'serp-item__title'})['href']\n",
    "    vacancion_organization = vacansion_info.find('a',{ 'class':'bloko-link'}).get_text()\n",
    "    try:\n",
    "        vacancion_money =  vacansion_info.find('span',{ 'data-qa':'vacancy-serp__vacancy-compensation'}).text\n",
    "    except:\n",
    "        vacancion_money = 'зарплата не указана'\n",
    "    print(f' вакансия: {vacansion_name}\\n организация: {vacancion_organization}\\n ссылка на вакансию: {vacansion_link}\\n зарплата: {vacancion_money} \\n *******')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932538ff",
   "metadata": {},
   "source": [
    "# ВЫВОД В ОДНОМ СКРИПТЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c455271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кем хотите работать?IT безопасность\n",
      "Показываю 20 вакансий \n",
      "\n",
      "вакансия: Специалист по информационной безопасности\n",
      "организация: ООО HeadHunter:: IT\n",
      "ссылка на вакансию: https://hh.ru/vacancy/68891020?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Администратор систем информационной безопасности\n",
      "организация: ООО HeadHunter:: IT\n",
      "ссылка на вакансию: https://hh.ru/vacancy/71324797?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Инженер по информационной безопасности\n",
      "организация: ООО HeadHunter:: IT\n",
      "ссылка на вакансию: https://hh.ru/vacancy/68898061?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Начальник отдела IT-инфраструктуры\n",
      "организация: НИИ Восход\n",
      "ссылка на вакансию: https://hh.ru/vacancy/76482669?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Менеджер по продажам IT-продуктов (без поиска)\n",
      "организация: Контур\n",
      "ссылка на вакансию: https://hh.ru/vacancy/69078236?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: от 80 000 руб. \n",
      " *******\n",
      "вакансия: Python developer\n",
      "организация: JuicyScore\n",
      "ссылка на вакансию: https://hh.ru/vacancy/76362476?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: 100 000 – 250 000 руб. \n",
      " *******\n",
      "вакансия: Специалист по информационной безопасности\n",
      "организация: ПАО «МТС» \n",
      "ссылка на вакансию: https://hh.ru/vacancy/70807060?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Эксперт сетевой безопасности\n",
      "организация: ПАО «МТС» \n",
      "ссылка на вакансию: https://hh.ru/vacancy/67496921?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Руководитель направления по информационной безопасности\n",
      "организация: Компания «СПОРТМАСТЕР», Управление бизнесами\n",
      "ссылка на вакансию: https://hh.ru/vacancy/73324588?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Инженер отдела информационной безопасности\n",
      "организация: ООО Люр АйТи\n",
      "ссылка на вакансию: https://hh.ru/vacancy/73236872?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: от 150 000 руб. \n",
      " *******\n",
      "вакансия: Менеджер по информационной безопасности\n",
      "организация: ООО РН-Карт\n",
      "ссылка на вакансию: https://hh.ru/vacancy/76563345?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Менеджер по информационной безопасности\n",
      "организация: ВТБ Капитал\n",
      "ссылка на вакансию: https://hh.ru/vacancy/76511422?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Специалист отдела безопасности ИТ\n",
      "организация: Hyundai AutoEver Rus\n",
      "ссылка на вакансию: https://hh.ru/vacancy/75900896?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Директор по информационной безопасности\n",
      "организация: АО Деловая среда\n",
      "ссылка на вакансию: https://hh.ru/vacancy/76216433?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Руководитель направления по информационной безопасности\n",
      "организация: ФБК\n",
      "ссылка на вакансию: https://hh.ru/vacancy/73497764?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Специалист по информационной безопасности (IT компания)\n",
      "организация: ООО Бизнес Система Телеком\n",
      "ссылка на вакансию: https://hh.ru/vacancy/76340403?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Инженер по информационной безопасности\n",
      "организация: АО К-ТЕХНОЛОГИИ\n",
      "ссылка на вакансию: https://hh.ru/vacancy/76492343?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Менеджер по информационной безопасности\n",
      "организация: Tele2\n",
      "ссылка на вакансию: https://hh.ru/vacancy/75596065?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Специалист отдела информационной безопасности (IT Департамент)\n",
      "организация: ИНВИТРО\n",
      "ссылка на вакансию: https://hh.ru/vacancy/75902853?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: зарплата не указана \n",
      " *******\n",
      "вакансия: Pre-sale (информационная безопасность)\n",
      "организация: ООО Комплаинс Софт\n",
      "ссылка на вакансию: https://hh.ru/vacancy/73998378?from=vacancy_search_list&query=IT+%D0%B1%D0%B5%D0%B7%D0%BE%D0%BF%D0%B0%D1%81%D0%BD%D0%BE%D1%81%D1%82%D1%8C\n",
      "зарплата: от 150 000 руб. \n",
      " *******\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "headers = {'user-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}\n",
    "vacancy = input('Кем хотите работать?')\n",
    "url = f'https://hh.ru/search/vacancy?text={vacancy}&from=suggest_post&salary=&area=1&ored_clusters=true&enable_snippets=true'\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "anchor = soup.find('div', {'class': 'vacancy-serp-content'})\n",
    "vacansions_all_info = anchor.find_all('div', {'class': 'serp-item'})\n",
    "print(f'Показываю {len(vacansions_all_info)} вакансий \\n')\n",
    "\n",
    "for vacansion_info in vacansions_all_info:\n",
    "    vacansion_name = vacansion_info.find('a',{ 'class':'serp-item__title'}).get_text()\n",
    "    vacansion_link = vacansion_info.find('a',{ 'class':'serp-item__title'})['href']\n",
    "    vacancion_organization = vacansion_info.find('a',{ 'class':'bloko-link'}).get_text()\n",
    "    try:\n",
    "        vacancion_money =  vacansion_info.find('span',{ 'data-qa':'vacancy-serp__vacancy-compensation'}).text\n",
    "    except:\n",
    "        vacancion_money = 'зарплата не указана'\n",
    "        \n",
    "    print(f'вакансия: {vacansion_name}\\n'\n",
    "          f'организация: {vacancion_organization}\\n'\n",
    "          f'ссылка на вакансию: {vacansion_link}\\n'\n",
    "          f'зарплата: {vacancion_money} \\n *******')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e9d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69734ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
