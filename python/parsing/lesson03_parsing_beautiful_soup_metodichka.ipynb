{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebb72e8",
   "metadata": {},
   "source": [
    "# Парсинг HTML. Beautiful Soup\n",
    "Оглавление:\n",
    "\n",
    "Beautiful Soup для сбора данных в HTML\n",
    "- Установка и начало работы\n",
    "-  Дерево синтаксического разбора\n",
    "- Атрибуты тегов\n",
    "- Навигация по дереву синтаксического разбора\n",
    "\n",
    "> parent\n",
    "\n",
    "> contents\n",
    "\n",
    "> string\n",
    "\n",
    "> next_sibling и previous_sibling\n",
    "\n",
    "> next и previous\n",
    "\n",
    "- Глоссарий\n",
    "- Дополнительные материалы\n",
    "- Домашнее задание\n",
    "- Используемая литература\n",
    "\n",
    "1. Познакомимся с библиотекой BeautifulSoup.\n",
    "2. Напишем первый парсер сайта с использованием этой библиотеки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c83763",
   "metadata": {},
   "source": [
    "### Beautiful Soup для сбора данных в HTML\n",
    "#### Установка и начало работы\n",
    "\n",
    "Парсить HTML мы будем с применением библиотеки Requests, а обрабатывать полученную структуру — с помощью библиотеки Beautiful Soup. Установим их, введя команды в терминале:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b52fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b6a63",
   "metadata": {},
   "source": [
    "Импортируем библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba00faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe13f5a",
   "metadata": {},
   "source": [
    "Чтобы посмотреть основные возможности Beautiful Soup, попробуем собрать все книги с первой\n",
    "страницы известного нам сайта Books to Scrape.\n",
    "\n",
    "Для начала сделаем GET-запрос на сайт:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799766c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "response = requests.get('http://example.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e1ddf",
   "metadata": {},
   "source": [
    "Теперь передадим полученный ответ в Beautiful Soup и укажем, какой парсер нам нужен. Создадим объект «суп»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17119a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa245aa0",
   "metadata": {},
   "source": [
    "### Дерево синтаксического разбора\n",
    "Дерево синтаксического разбора — структуры данных Beautiful Soup, которые создаются по мере синтаксического разбора документа. Объект парсера (экземпляр класса BeautifulSoup) обладает большой глубиной вложенности связанных структур данных, соответствующих структуре документа\n",
    "XML или HTML. Объект парсера состоит из объектов двух других типов:\n",
    "\n",
    "● объектов Tag, которые соответствуют тегам, к примеру, `<div>` и `<p>`;\n",
    "\n",
    "● объекты NavigableString, соответствующие таким строкам, как In stock или Sapiens: A Brief History ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5533a1",
   "metadata": {},
   "source": [
    "### Атрибуты тегов\n",
    "У тегов HTML есть атрибуты: например, у каждого тега `<img>` в приведённом выше примере HTML есть атрибуты class, src и alt. К атрибутам тегов можно обращаться таким же образом, как если бы объект Tag был словарём:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98abb9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head.parent.name\n",
    "# 'html'\n",
    "soup.head.parent.parent.__class__.__name__\n",
    "# 'BeautifulSoup'\n",
    "soup.parent == None\n",
    "# true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e42b1b",
   "metadata": {},
   "source": [
    "#### contents\n",
    "Parent перемещает нас вверх по дереву синтаксического разбора. С помощью contents мы перемещаемся вниз по дереву синтаксического разбора. Сontents — упорядоченный список, состоящий — из объектов Tag и NavigableString, содержащихся в элементе страницы (page element).\n",
    "\n",
    "#### string\n",
    "Если у тега есть только один дочерний узел, который будет строкой, этот узел будет доступен через tag.string точно так же, как и через tag.contents[0].\n",
    "\n",
    "#### next_sibling и previous_sibling\n",
    "Эти элементы позволяют переходить к следующему или предыдущему элементу на этом же уровне дерева синтаксического разбора. Эти способы перемещения довольно часто используются, когда у вас есть одинаковые элементы с абсолютно одинаковыми атрибутами, и вы точно знаете, что вам нужен именно второй.\n",
    "\n",
    "#### next и previous\n",
    "Эти элементы позволяют передвигаться по элементам документа в том порядке, в котором они были обработаны парсером, а не в порядке появления в дереве.\n",
    "\n",
    "Спарсим информацию о каждой книге с первой страницы. Для начала нам надо понять, где находится каждая книга. Нажимаем вот на этот значок в левом углу нашего инспектора и наводим на книгу. Видим, что вся информация о книге находится в теге article, родителем которого является тег li.\n",
    "Давайте посмотрим, сколько у нас всего элементов с тегом article на странице, для этого в строку поиска вводим article и нажимаем enter. Поиск показывает 20 элементов, и на самом верху страницы\n",
    "мы видим, что нам показано 20 элементов. Таким образом, чтобы выбрать все блоки с книгами с первой страницы, нам надо написать следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b481f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "books = soup.find_all('article')\n",
    "books2 = soup.select('article')\n",
    "print(len(books), len(books2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6bc678",
   "metadata": {},
   "source": [
    "Мы использовали оба метода, и итоговая длина списков у нас получилась одинаковой. Давайте посмотрим на первый элемент списка books — print(books[0]). Как видите, это элемент HTML, то есть, обращаясь к нему, мы можем применять все методы, которые доступны для супа.\n",
    "\n",
    "Сохраним его в переменную book и протестируем для него получение названия, обложки, цены и наличия. Будем обращаться к элементу book и вызывать для него методы, доступные для супа. Рассмотрим разные способы получения информации.\n",
    "\n",
    "Первое, что нам надо получить — название. Мы внутри тега article, так что всё, что выше, нас не интересует. Название находится в теге `<а>`, который вложен в тег `<h3>`. Возьмём этот тег за основу и спустимся вниз. Обратите внимание: если текст мы возьмём у тега `<а>`, то получим неполное название, так что нам надо брать атрибут title. Итак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eae862",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = book.find('h3').find('a')['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0e52e",
   "metadata": {},
   "source": [
    "Теперь найдём цену. Возвращаемся на сайт. Цена находится в теге `<p>` с классом `price_color`, который вложен в тег `<div>`. Внутри этого же тега лежит и информация о наличии книги в магазине. Сперва получим информацию о наличии товара. Мы можем сделать это двумя способами.\n",
    "\n",
    "Первый — используя метод find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "instock = book.find('p', attrs={'class':['instock', 'availability']}).text\n",
    "print(instock)\n",
    "print(instock.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134683f0",
   "metadata": {},
   "source": [
    "Метод strip мы используем, чтобы избавиться от лишних пробелов и энтеров у текста.\n",
    "\n",
    "Второй — используя метод `select_one` и указание неполного класса. Этот метод удобен, когда вы точно знаете, что внутри html находится единственный тег с указанным классом или вам нужен первый тег из множества. Метод `select_one` выберёт первый элемент, который попадёт под ваше описание. Давайте проверим, что у нас на странице ровно 20 элементов с классом instock. Для этого в поиске пишем точкаi nstock. Да, всё верно, элементов ровно 20 В этом случае используем второй способ получения статуса о наличии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "instock = book.select_one('div[class=product_price] p[class*=instock]').text\n",
    "print(instock)\n",
    "print(instock.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382db8b8",
   "metadata": {},
   "source": [
    "Вы видите, что мы указали и родительский элемент. А для тега `<p>` — класс со звёздочкой, так как на странице у него есть ещё один класс — `availability`. Вообще, указывать точный путь до элементов довольно нудно и долго, но иногда только так вы можете получить нужную информацию.\n",
    "\n",
    "Теперь попробуем получить цену. Самое простое решение — найти тег `<p>` с классом `price_color`, но лучше разобрать и другие методы BeautifulSoup. Так что давайте воспользуемся методом `find_previous_sibling()`, который позволяет искать предыдущие теги одного уровня, а `find_next_sibling()`\n",
    "ищет следующие теги одного уровня. Внутри мы указываем, какой тег хотим найти. Это удобно в тех случаях, когда много одинаковых тегов, а классы ничем не отличаются. Если вы добавите `s` в конце — `find_next_siblings()` и `find_previous_siblings()` — то вам вернётся список. Итак, ищем цену. Копируем уже найденную сущность `instock`, убираем получение текста и добавляем `find_previuos_sibling()`.\n",
    "Внутри указываем тег `<p>`. Смотрим, что получилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "instock = book.select_one('div[class=product_price] p[class*=instock]')\n",
    "price = instock.find_previous_sibling(‘p')\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5c4bc5",
   "metadata": {},
   "source": [
    "Как видите, мы нашли цену. Осталось найти изображение обложки. Оно лежит в теге `<img>`, вложенном в тег `<а>`, родителем которого является тег `<div>` с классом `image_container`. У тега `<img>` нам надо получить\n",
    "атрибут `src`. Давайте всё это запишем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0665635",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = soup.find('div', attrs={'class': 'image_container'}).find('img')['src']\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580ad02a",
   "metadata": {},
   "source": [
    "Обратите внимание, что ссылка у нас неполная. Желательно сохранять полные ссылки, чтобы вы могли воспользоваться ими без необходимости открывать сайт и вспоминать, как именно выглядит ссылка. Чтобы понять, какая ссылка полная, можно кликнуть на картинку и посмотреть, что будет в адресной строке. Копируем недостающую часть. Теперь сохраним переменную `image_link` таким образом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_link = ‘https://books.toscrape.com/’+image\n",
    "print(image_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbb094",
   "metadata": {},
   "source": [
    "Теперь у нас есть полная ссылка на изображение обложки.\n",
    "\n",
    "Последнее, что нам осталось сделать, чтобы спарсить все книги с первой страницы сайта, — создать цикл, в котором мы будем идти по каждой книге, извлекать название, цену, обложку и наличие, сохранять всё это в словарь, а словарь сохранять в список. Таким образом, в итоге у нас должен\n",
    "получиться список из 20 книг с первой страницы сайта.\n",
    "\n",
    "Давайте объединим все участки кода, которые мы уже написали и добавим совсем немного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_list = []\n",
    "\n",
    "for book in books:\n",
    "    title = book.find('h3').find('a')['title']\n",
    "    instock = book.select_one('div[class=product_price] p[class*=instock]').text.strip()\n",
    "    price = book.select_one('div[class=product_price] p[class*=instock]').find_previous_sibling('p').text.strip()\n",
    "    image = soup.find('div', attrs={'class': 'image_container'}).find('img')['src']\n",
    "    image_link = 'https://books.toscrape.com/'+image\n",
    "    book_dict = {\n",
    "        'Image': image_link,\n",
    "        'Title': title,\n",
    "        'Price': price,\n",
    "        'Instock': instock\n",
    "        }\n",
    "    \n",
    "books_list.append(book_dict)\n",
    "print(len(books_list))\n",
    "pprint(books_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c27a30",
   "metadata": {},
   "source": [
    "В нашем итоговом списке 20 книг, как и должно быть. При просмотре этого списка мы видим, что он состоит из 20 словарей, в каждом из которых находится вся нужная информация о книге. \n",
    "\n",
    "Так же в Beautiful Soup есть много других полезных методов: например, `find_parent()`, `find_next()` и\n",
    "`find_previous()`, которые помогают найти родительский тег, следующий или предыдущий тег соответственно. При работе с любыми библиотеками полезно пользоваться их документацией или искать ответы на вопросы на сайте StackOverflow по тегу BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad43e3",
   "metadata": {},
   "source": [
    "### Глоссарий\n",
    "- `HTML (HyperText Markup Language)` — язык гипертекстовой разметки. Интерпретируется браузерами, в результате чего форматированный текст отображается на экране. HTML-страницы передаются от сервера к клиенту по протоколу HTTP в виде обычного или зашифрованного текста.\n",
    "\n",
    "- `HTML-теги` — используются для разграничения начала и конца элементов в разметке.\n",
    "\n",
    "- `Атрибуты` — свойства тега, дающие дополнительные возможности форматирования текста.\n",
    "\n",
    "- `DOM (Document Object Model)` — не зависящий от платформы и языка программный интерфейс, позволяющий программам и скриптам получить доступ к содержимому HTML-, XHTML- и XML- документов, а также изменять содержимое, структуру и оформление таких документов.\n",
    "\n",
    "- `Библиотека Beautiful Soup` — парсер lxml, который преобразует наш HTML-код в DOM и обрабатывает полученную структуру.\n",
    "\n",
    "- `Дерево синтаксического разбора` — структуры данных Beautiful Soup, которые создаются по мересинтаксического разбора документа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb646aac",
   "metadata": {},
   "source": [
    "### Дополнительные материалы\n",
    "1. Документация BeautifulSoup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a63974",
   "metadata": {},
   "source": [
    "### Используемая литература\n",
    "1. Базовая структура HTML .\n",
    "2. Элементы HTML/CSS .\n",
    "3. Объектная модель документа .\n",
    "4. Стандарт HTML5 .\n",
    "5. Документация Beautifull Soup .\n",
    "6. Документации/BeautifulSoup ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
